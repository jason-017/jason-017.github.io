---
title: "[airflow] 3. airflow 트러블슈팅 여정기"
categories:
 - airflow
excerpt: " "
tags:
 - airflow
 - data engineer
 - dataflow
 - ETL
 - docker
---
## 0. 환경
- docker OS: ubuntu
- airflow version: airflow 2.1.4
- metaDB: mysql 5.7
## 1. airflow 관련 트러블슈팅
- mysql로 airflow DB 초기화할 때 ModuleNotFoundError: No module named 'MySQLdb' 발생하면 아래 순서대로 수행 후 재시도
  - centos
    ```
    $ sudo yum install mysql-devel
    $ pip3 install 'apache-airflow[mysql]'
    ```
  - ubuntu
    ```
    $ pip install mysqlclient
    $ apt-get install mysql
    $ pip3 install 'apache-airflow[mysql]'
    ```
- mysql로 airflow DB 초기화할 때 아래 에러 발생하면 meta DB의 /etc/mysql/mysql.conf.d/mysqld.cnf에서 explicit_defaults_for_timestamp=1로 변경 후 mysql 재실행(service mysql restart)
    ```
    raise Exception("Global variable explicit_defaults_for_timestamp needs to be on (1) for mysql")
    Exception: Global variable explicit_defaults_for_timestamp needs to be on (1) for mysql 
    ```
- docker centos run 수행할 때 'Failed to get D-Bus connection: Operation not permitted' or 'Failed to mount tmpfs at /run: Operation not permitted' 오류 해결을 위해 privileged 옵션 사용
  `docker run --privileged -d -p 1099:8080 -p 1022:22 --name airflow centos:centos7.9.2009 /sbin/init`
- pyodbc로 tibero 연결할 때 'PSM compilation error.' 발생할 경우, 아래와 같이 encoding & decoding 문제를 해결해줘야 함.
- cp949는 한글 인코딩 방식으로 euc-kr의 확장버전임.
  ```python
  import pyodbc  
  conn = pyodbc.connect('DSN=tibero6;UID=biqa;PWD=tmax;')  
  conn.setdecoding(pyodbc.SQL_CHAR, encoding='cp949')  
  conn.setdecoding(pyodbc.SQL_WCHAR, encoding='cp949')  
  conn.setencoding(encoding='cp949')  
  cur = conn.cursor()  
  cur.execute('SQL')  
  rows = cur.fetchall()
  ```
- docker centos7에 airflow 2.0.0을 올렸을 때 ascii 코덱이 한글을 처리하지 못해서 발생하는 에러이고, OS를 ubuntu로 변경하고 airflow 2.1.4로 버전 업그레이드 하니 정상 동작함.
  ```bash
  Process DagFileProcessor49762-Process:
  Traceback (most recent call last):
    File "/usr/lib64/python3.6/multiprocessing/process.py", line 258, in _bootstrap
      self.run()
    File "/usr/lib64/python3.6/multiprocessing/process.py", line 93, in run
      self._target(*self._args, **self._kwargs)
    File "/usr/local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 186, in _run_file_processor
      callback_requests=callback_requests,
    File "/usr/local/lib/python3.6/site-packages/airflow/utils/session.py", line 65, in wrapper
      return func(*args, session=session, **kwargs)
    File "/usr/local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 648, in process_file
      dagbag.sync_to_db()
    File "/usr/local/lib/python3.6/site-packages/airflow/utils/session.py", line 65, in wrapper
      return func(*args, session=session, **kwargs)
    File "/usr/local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 549, in sync_to_db
      reraise=True,
    File "/usr/local/lib/python3.6/site-packages/tenacity/__init__.py", line 390, in __iter__
      do = self.iter(retry_state=retry_state)
    File "/usr/local/lib/python3.6/site-packages/tenacity/__init__.py", line 356, in iter
      return fut.result()
    File "/usr/lib64/python3.6/concurrent/futures/_base.py", line 425, in result
      return self.__get_result()
    File "/usr/lib64/python3.6/concurrent/futures/_base.py", line 384, in __get_result
      raise self._exception
    File "/usr/local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 560, in sync_to_db
      DAG.bulk_write_to_db(self.dags.values(), session=session)
    File "/usr/local/lib/python3.6/site-packages/airflow/utils/session.py", line 62, in wrapper
      return func(*args, **kwargs)
    File "/usr/local/lib/python3.6/site-packages/airflow/models/dag.py", line 1900, in bulk_write_to_db
      DagCode.bulk_sync_to_db([dag.fileloc for dag in orm_dags])
    File "/usr/local/lib/python3.6/site-packages/airflow/utils/session.py", line 65, in wrapper
      return func(*args, session=session, **kwargs)
    File "/usr/local/lib/python3.6/site-packages/airflow/models/dagcode.py", line 122, in bulk_sync_to_db
      orm_dag_code.source_code = cls._get_code_from_file(orm_dag_code.fileloc)
    File "/usr/local/lib/python3.6/site-packages/airflow/models/dagcode.py", line 175, in _get_code_from_file
      code = f.read()
    File "/usr/lib64/python3.6/encodings/ascii.py", line 26, in decode
      return codecs.ascii_decode(input, self.errors)[0]
  UnicodeDecodeError: 'ascii' codec can't decode byte 0xec in position 370: ordinal not in range(128)
  ```



