---
title: "프로그래머스 데이터 엔지니어링_1주차"
excerpt: "[스터디/6기] 실리콘밸리에서 날아온 데이터 엔지니어링 스타터 키트 with Python"

categories:
 - data engineering
tags:
 - python
 - data
 - data engineer
 - programmers
---

### 프로그래머스 데이터 엔지니어링_1주차

url: [[스터디/6기] 실리콘밸리에서 날아온 데이터 엔지니어링 스타터 키트 with Python](https://programmers.co.kr/learn/courses/12916){:target="_blank"}

응용통계학과와 소프트웨어학과를 전공으로 선택하면서 자연스럽게 데이터 분석가를 목표로 준비하게 됐는데, 준비하는 과정에서 데이터 엔지니어링의 매력에 빠지게 됐습니다. 그러나, 데이터 분석에 비해 시중에 출시된 교육이나 가이드가 크게 없기도 했고, 여러 개인적인 사정으로 직군 뿐만 아니라 다른 요소들도 함께 고려하게 되면서 현재는 DB 관련 직군에서 근무를 하고 있습니다. 일을 하며 데이터 엔지니어링 관련 세션을 찾던 중, 프로그래머스에서 진행하는 '실리콘밸리에서 날아온 데이터 엔지니어링 스타터 키트 with Python'을 알게 되었습니다. <br>
해당 세션에 참여하면서 data engineering 뿐만 아니라 career와 삶을 바라보는 다양한 관점 또한 전해들을 수 있어서 매우  값진 세션이라는 생각이 드는 것 같습니다.



#### career에 대한 강사님의 생각

- 매번 자신이 부족하다 느껴 도전하지 않고 공부만 하기보다는, 기본적으로 요구되는 지식과 실력을 쌓고 빠르게 도전하는 편이 낫다.

- 데이터 엔지니어의 경우, SQL, airflow, python이 기본적으로 요구된다. 실제 업무에서 다양한 툴들을 매우 많이 사용하는데 취업을 위해서는 SQL, python, airflow 등의 기본 스킬셋을 탑재하자! 또한, 주니어가 spark를 명확히 알고 활용하기 힘들다. spark 공부의 필요성은 자연스럽게 느끼게 될 것이기 때문에, 시작부터 spark 공부에 대한 부담을 가질 필요가 없다.
  -> 기본에 충실하고 필요하면 공부하자!





- 작은 성공의 연속으로 자신감을 갖는 것이 매우 중요

- 어렸을 때 다양한 것을 시도해보고, 나한테 맞다고 판단되는 것에 집중하자.

  - 30대 후반이 되기 전까지 exploits(과업, 업적)을 달성할 수 있는 직군을 정하면 충분히 행복할 수 있다.

- full time으로 6개월은 집중해봐야 잘 맞는지 알 수 있고 자신감도 생긴다. 때문에, 포기하지 말고 6개월 후에 결정하는 것을 추천한다.

- 다른 사람이랑 비교해서 기죽지 말고, 어제의 내가 발전하는 방향만 생각하면 된다. 잘하는 사람들의 대부분은 해당 공부를 먼저 접하고 많은 시간을 들인 상태일 것이다.

- 많은 기업들이 water fall에서 agile 방식으로 변해가고 있다. 흐름이 빠르기 때문에 개인의 삶도 agile 방식으로 사는 것이 낫다고 생각한다.

  - 예를 들어 프로젝트를 진행할 때 일단 프로젝트 사이클을 한바퀴 돌린 후, 과정과 결과를 보면서 필요한 부분이 무엇이고 어떤 알고리즘을 적용시킬지 등을 결정하는 게 더 나은 편이다.



#### 데이터 조직

- 데이터 조직은 일반적으로 내부 직원들을 서포트하는 부수적인 조직
  - **사실, 데이터로 바로 돈을 벌 수 있는 구조가 아님.**
  - 반도체 회사의 경우, 반도체 수율을 높이기 위해 데이터 기반으로 공정을 개선시키는 것이지, 반도체 자체를 만드는데 활용되지는 않음.



- 데이터를 활용한 decision 방법
  - data driven decisions
    - 무조건 데이터에서 나온 결과를 따라가는 결정 방법
    - 결정에 대한 기준이 없고 애매할 때 도움이 될 수 있다.
    - 혁신이 발생하지 않음
    - 개인적인 생각이지만, 책임을 질 사람이 없다는 것도 문제가 될 것 같다.
  - data informed decisions
    - 데이터에서 나온 결과를 참고하여 결정을 내리는 방법
    - 혁신 발생 가능성 있음



- 데이터 조직 구성: 엔지니어, 분석가, 과학자(데이터팀은 파이썬 사용 비율이 굉장히 높음)
  - 데이터 분석가
    - 내부 직원을 상대로 업무 수행
    - data warehouse에 적재되어 있는 data로 summary table 만들어서 사용 및 제공
    - raw data를 기반으로 summary table 생성(데이터를 필요할 때마다 raw data 직접 불러와서 join하는 것은 굉장히 비효율적)
  - 데이터 과학자
    - 외부 고객(직접적인 서비스)을 상대로 업무 수행
    - 알고리즘을 통해 고객 경험 향상시킴(ex. 상품 quality를 향상시키기 위해 예측 모델 building)
    - 통계 지식이 수학 지식보다 훨씬 중요하다고 판단됨.
  - 데이터 엔지니어
    - 고품질의 신뢰할 수 있는 데이터를 모아줘야 함.
    - 데이터 엔지니어는 raw data를 웨어하우스에 모아주는 역할이며 어떤 데이터들이 모이는지 다 아는 것은 불가능한 일
    - 어딘가에 있는 데이터를 웨어하우스로 제대로 복사하고 적재해주는 것이 제일 중요
      -> 이것을 분석가가 입맛에 맞게 summary table 구성 및 생성
    - 데이터 워크플로우는 현재 에어플로우가 ETL 스탠다드 자리잡음.
  - ML engineer
    - 데이터 엔지니어 + 데이터 분석가
    - 직접 데이터 엔지니어링을 통해 원하는 데이터를 추출하고 데이터를 분석



- 모델의 경우 간단하게 만들어서 사이클을 한바퀴 돌려보는 것이 중요(agile 방식)
  - 한번 돌려보면 어느 팀과 협업을 해야할지, 무엇이 필요한지 빠르게 인지 가능
  - 이후 지속적으로 A/B 테스트 하는 것이 중요(데이터 엔지니어가 하는 경우도 많고 매우매우매우 중요)



- 솔루션은 간단할수록 좋다.
  - pandas로 할 수 있는 것을 굳이 spark로 할 필요가 없다.
  - 많이 쓰고 유행한다고 따라가는 게 좋은 게 아니다. 적절한 솔루션을 적용하는 게 좋다.
  - 간단한 로직으로 해결할 수 있는 문제를 복잡한 로직으로 해결하려고 하지 말자.
  - 그래서 일단 간단하게 사이클을 한바퀴 돌아보는 것이 중요! -> 적절한 솔루션 및 로직을 선택할 수 있음.



- 코호트 분석: 유저를 그루핑하여 분석하는 기법
  - 각 플랫폼별로 유입된 유저로 나눠서 분석
  - ex) 틱톡에서 유입된 유저, 유튜브에서 유입된 유저 등으로 나눠서 비교 분석



- production DB vs data warehouse
  - production DB
    - 응답 속도가 굉장히 중요
    - 운영에 필요한 최소한의 데이터만 저장됨.
    - 백엔드 개발자나 DBA들이 보통 관리
  
  - data warehouse
    - 내부 데이터팀 또는 직원들을 위한 DB
    - 응답 속도가 production DB에 비해 빠를 필요가 없으며 처리할 수 있는 데이터의 규모가 더욱 중요
    - **온갖 종류의 데이터가 모여있으며 데이터 엔지니어가 관리**
    - 데이터 분석가가 production DB에 붙어서 데이터 분석할 경우, 서비스 응답 속도에 큰 영향을 미치기 때문에 쓰면 안된다.
      **-> 때문에 분석을 위해 data warehouse 구축이 중요**
    - 보통 API를 호출해서 ETL 하는 경우가 대다수이며, production DB는 mysql 등에서 호출되어 ETL 진행되는 경우가 많음.
    - **결국 운영용 DB랑 내부에서 편하게 사용할 DB를 나누기 위해 컨셉을 나눠놓은 형태!**
    - 데이터 웨어하우스는 컨셉일 뿐이다. 단지 데이터 사이즈가 크기 때문에 사용하는 것이다. 만약 규모가 작으면 mysql 등의 RDB를 활용해도 무방 -> 관찰하면서 데이터 웨어하우스로 넘어가는 타이밍도 잘 잡아야 한다.



#### PREVIEW

- looker가 실리콘벨리에서 현재 가장 많이 사용되는 대쉬보드, 이전까지는 태블로가 가장 많이 사용됨.
  - looker는 비용이 많이 들기 때문에 무료 대쉬보드인 superset을 활용하는 경우도 있음.



- pandas, spark
  - pandas: 서버 한대에 들어가는 작은 데이터를 다루는 것
  - spark: 여러 클러스터에 들어가는 큰 데이터를 다루는 것
  - pandas와 spark에서 데이터 다루는 컨셉은 거의 비슷함.



- A/B 테스트
  - 단일 변수에 대한 두 가지 버전을 비교하는 방법
  - A는 기존 버전, B는 수정 버전으로 비교하는 방법으로 단일 변수로 진행한다는 점이 중요
  - ex) 웹사이트에서 버튼 하나의 색상을 다르게 하여 클릭 횟수 비교